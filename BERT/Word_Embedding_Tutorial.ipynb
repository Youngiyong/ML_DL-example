{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "dba042d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4f2b584e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d701bc49",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5a14bf56",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import BertTokenizer, BertModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0eae9a7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c2f8f4ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "729a7e22",
   "metadata": {},
   "outputs": [],
   "source": [
    "logging.basicConfig(level=logging.INFO)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "40fe8e1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b1337d81",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = BertTokenizer.from_pretrained('bert-base-multilingual-cased')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "95d5f1cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "text = \"임베딩을 시도할 문장이다.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ce474701",
   "metadata": {},
   "outputs": [],
   "source": [
    "marked_text = \"[CLS] \" + text + \" [SEP]\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "07502486",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenized_text = tokenizer.tokenize(marked_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "de56e94f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['[CLS]', '임', '##베', '##딩', '##을', '시', '##도', '##할', '문', '##장이', '##다', '.', '[SEP]']\n"
     ]
    }
   ],
   "source": [
    "# Print out the tokens.\n",
    "print(tokenized_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "543a45cd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['浩',\n",
       " '浪',\n",
       " '浬',\n",
       " '浮',\n",
       " '浴',\n",
       " '海',\n",
       " '浸',\n",
       " '涂',\n",
       " '涅',\n",
       " '涇',\n",
       " '消',\n",
       " '涉',\n",
       " '涌',\n",
       " '涎',\n",
       " '涓',\n",
       " '涕',\n",
       " '涙',\n",
       " '涛',\n",
       " '涝',\n",
       " '涟']"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(tokenizer.vocab.keys())[5000:5020]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "344d5eba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a new example sentence with multiple meanings of the word \"bank\"\n",
    "text = \"배를 타고 여행을 간다.\" \\\n",
    "       \"추석에 먹은 배가 맛있었다.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "6052f95b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add the special tokens.\n",
    "marked_text = \"[CLS] \" + text + \" [SEP]\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f4b8e94c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Split the sentence into tokens.\n",
    "tokenized_text = tokenizer.tokenize(marked_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "f6df37f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Map the token strings to their vocabulary indeces.\n",
    "indexed_tokens = tokenizer.convert_tokens_to_ids(tokenized_text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "6987d031",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CLS]           101\n",
      "배             9,330\n",
      "##를          11,513\n",
      "타             9,845\n",
      "##고          11,664\n",
      "여             9,565\n",
      "##행을         88,904\n",
      "간             8,845\n",
      "##다          11,903\n",
      ".               119\n",
      "추             9,765\n",
      "##석          40,958\n",
      "##에          10,530\n",
      "먹             9,266\n",
      "##은          10,892\n",
      "배             9,330\n",
      "##가          11,287\n",
      "맛             9,254\n",
      "##있          119,192\n",
      "##었다         17,706\n",
      ".               119\n",
      "[SEP]           102\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Display the words with their indeces.\n",
    "for tup in zip(tokenized_text, indexed_tokens):\n",
    "    print('{:<12} {:>6,}'.format(tup[0], tup[1]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a9e9282",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "504707fc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9008a3c9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ac3df70",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef5f6a6c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
